import torch
import torch.nn as nn

class BEVGRU(nn.Module):
    def __init__(self, input_channels, hidden_dim, output_dim, height, width):
        super(BEVGRU, self).__init__()
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.height = height
        self.width = width

        # CNNì„ ì‚¬ìš©í•˜ì—¬ feature dimensionì„ hidden_dimìœ¼ë¡œ ë³€í™˜
        self.feature_extractor = nn.Sequential(
        nn.Conv2d(input_channels, hidden_dim // 2, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.Conv2d(hidden_dim // 2, hidden_dim, kernel_size=3, stride=1, padding=1),
        nn.ReLU(),
        nn.AdaptiveAvgPool2d((1, 1)),  # [batch*seq_len, hidden_dim, 1, 1]
        nn.Flatten()  # [batch*seq_len, hidden_dim]
    )

        # GRU Layer
        self.gru = nn.GRU(hidden_dim, hidden_dim, batch_first=True)

        # Fully Connected Layer to project GRU output
        self.fc = nn.Linear(hidden_dim, output_dim * height * width)

    def forward(self, x, current_index=2, future_steps=2):
        batch_size, seq_len, channel, height, width = x.size()
        
        # CNNì„ í†µí•´ feature dimension ì¤„ì´ê¸°
        x = x.view(batch_size * seq_len, channel, height, width)  # [batch*seq_len, channel, height, width]
        x = self.feature_extractor(x)  # [batch*seq_len, hidden_dim]
        x = x.view(batch_size, seq_len, self.hidden_dim)  # [batch, seq_len, hidden_dim]

        # GRU ì²˜ë¦¬
        gru_out, _ = self.gru(x)  # [batch, seq_len, hidden_dim]

        # ë¯¸ë˜ ì˜ˆì¸¡ (Future Prediction)
        last_hidden = gru_out[:, -1, :].unsqueeze(1)  # [batch, 1, hidden_dim]
        future_pred = []

        for _ in range(future_steps):
            last_hidden, _ = self.gru(last_hidden)  # [batch, 1, hidden_dim]
            future_pred.append(self.fc(last_hidden).view(batch_size, 1, -1, self.height, self.width))

        future_pred = torch.cat(future_pred, dim=1)  # [batch, future_steps, output_dim, height, width]

        # Project GRU output to spatial dimensions
        output = self.fc(gru_out)  # [batch, seq_len, output_dim * height * width]
        output = output.view(batch_size, seq_len, self.output_dim, self.height, self.width)  # [batch, seq_len, output_dim, height, width]

        # Concatenate past, present, and future
        total_output = torch.cat([output, future_pred], dim=1)  # [batch, seq_len + future_steps, output_dim, height, width]

        # Extract current & future BEV
        current_bev = total_output[:, current_index].unsqueeze(1)  # [batch, 1, output_dim, height, width]
        future_bev = total_output[:, current_index + 1 : current_index + 1 + future_steps]  # [batch, 2, output_dim, height, width]

        return total_output, future_bev
    
class EgoStateGRU(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_layers=1):
        """
        Args:
            input_dim (int): Input feature dimension (e.g., 112 for ego state embedding).
            hidden_dim (int): Hidden state size of the GRU.
            output_dim (int): Output feature dimension for the GRU output projection.
            num_layers (int): Number of GRU layers.
        """
        super(EgoStateGRU, self).__init__()
        self.hidden_dim = hidden_dim
        self.output_dim = output_dim
        self.num_layers = num_layers

        # GRU Layer
        self.gru = nn.GRU(input_dim, hidden_dim, num_layers=num_layers, batch_first=True)

        # Fully Connected Layer to project to desired output dimension
        self.fc = nn.Linear(hidden_dim, output_dim)

        # Future Predictionì„ ìœ„í•œ Linear Layer ì¶”ê°€
        self.future_fc = nn.Linear(output_dim, input_dim)

    def forward(self, x, future_steps=2):
        """
        Args:
            x (torch.Tensor): Input tensor of shape [batch_size, seq_len=3, input_dim].
            future_steps (int): Number of future steps to predict (default: 2).
        
        Returns:
            torch.Tensor: Output tensor of shape [batch_size, future_steps, output_dim].
        """
        batch_size, seq_len, _ = x.size()

        # GRU forward pass (ê³¼ê±° 2ê°œ + í˜„ì¬)
        gru_out, hidden_state = self.gru(x)  # [batch_size, seq_len, hidden_dim]

        # Initialize future predictions
        future_pred = []

        # ğŸ”¹ Future step inputì„ ë§ˆì§€ë§‰ ì‹¤ì œ ì…ë ¥ì˜ ë³€í˜•ê°’ìœ¼ë¡œ ì„¤ì •
        future_input = self.future_fc(self.fc(gru_out[:, -1, :])).unsqueeze(1)  # [batch_size, 1, input_dim]

        for _ in range(future_steps):
            # ğŸ”¹ GRUë¡œ future step ì˜ˆì¸¡
            next_out, hidden_state = self.gru(future_input, hidden_state)
            next_output = self.fc(next_out.squeeze(1))  # [batch_size, output_dim]

            # ğŸ”¹ Append prediction
            future_pred.append(next_output.unsqueeze(1))  # [batch_size, 1, output_dim]

            # ğŸ”¹ ë‹¤ìŒ stepì˜ inputì„ ì—…ë°ì´íŠ¸ (ì´ì „ ì˜ˆì¸¡ê°’ì„ ë‹¤ì‹œ ì…ë ¥ìœ¼ë¡œ ì‚¬ìš©)
            future_input = self.future_fc(next_output).unsqueeze(1)  # [batch_size, 1, input_dim]

        # ğŸ”¹ Concatenate future predictions
        future_pred = torch.cat(future_pred, dim=1)  # [batch_size, future_steps, output_dim]

        return future_pred
    
class FutureControlGRU(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim):
        """
        Args:
            input_dim: GRU ì…ë ¥ ì°¨ì› (í˜„ì¬ì™€ ë¯¸ë˜ í”„ë ˆì„ ì •ë³´ í¬í•¨)
            hidden_dim: GRUì˜ hidden state í¬ê¸°
            output_dim: ì¶œë ¥ ì°¨ì› ([throttle, steer, brake])
        """
        super(FutureControlGRU, self).__init__()
        self.gru = nn.GRU(input_dim, hidden_dim, batch_first=True)
        self.fc = nn.Linear(hidden_dim, output_dim)  # GRU hidden stateì—ì„œ ì œì–´ê°’ ì¶”ì¶œ

    def forward(self, x):
        """
        Args:
            x: [batch_size, seq_len, input_dim] - í˜„ì¬ì™€ ë¯¸ë˜ í”„ë ˆì„ ì •ë³´ë¥¼ í¬í•¨í•œ ì‹œí€€ìŠ¤ ì…ë ¥
        Returns:
            future_control_value: [batch_size, output_dim] - ë¯¸ë˜ ì œì–´ê°’
        """
        output, _ = self.gru(x)  # GRU ëª¨ë“  ì‹œì  ì¶œë ¥: [batch_size, seq_len, hidden_dim]
        future_control_value = self.fc(output[:, -1])  # ë§ˆì§€ë§‰ ì‹œì  ì¶œë ¥ ì‚¬ìš©: [batch_size, output_dim]
        return future_control_value